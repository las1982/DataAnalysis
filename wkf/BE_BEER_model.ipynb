{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UC2: BE_BEER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from wkf.Columns import Columns\n",
    "\n",
    "main_dir = '/media/alex/data/alex/work/wkf/nielsen/UC2/BE_BEER/'\n",
    "train = pd.read_csv(main_dir + 'data/train.csv', sep=',', quotechar='\"', encoding='latin-1')\n",
    "test = pd.read_csv(main_dir + 'data/test.csv', sep=',', quotechar='\"', encoding='latin-1')\n",
    "\n",
    "# normalize headers\n",
    "train = train.rename(columns=lambda x: re.sub('[^0-9a-zA-Z]', '_', x).lower())\n",
    "test.columns = map((lambda x: re.sub('[^0-9a-zA-Z]', '_', x).lower()), test.columns)\n",
    "\n",
    "columns = Columns(country='BE', category='BEER', use_case='uc2', data_set_csv=main_dir + 'data/train.csv')\n",
    "predictors = columns.get_input_cols()\n",
    "# remove from predictors column which is not in test set in this case\n",
    "predictors.pop(predictors.index(u'_be_loc_gamm___m_gamme'))\n",
    "predictor = 'item_description'\n",
    "responses = columns.get_output_cols()\n",
    "response = 'brand_1'\n",
    "X_train = train[predictor]\n",
    "y_train = train[response].iloc[0:]\n",
    "X_test = test[predictor]\n",
    "y_test = test[response].iloc[0:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5423,) (5423,) (201,) (201,)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "# print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "# print('\\n\\nX_train shape: ', X_train.shape)\n",
    "# print X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false,
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'10',\n u'1000ml',\n u'11',\n u'12',\n u'1200ml',\n u'125',\n u'13',\n u'14',\n u'15',\n u'1500ml',\n u'1664',\n u'1673',\n u'18',\n u'180ml',\n u'1830',\n u'1858',\n u'1886',\n u'1892',\n u'1900',\n u'19500ml',\n u'20000ml',\n u'2000ml',\n u'200ml',\n u'2013',\n u'25',\n u'250ml',\n u'275ml',\n u'277ml',\n u'28',\n u'280ml',\n u'284ml',\n u'285ml',\n u'290ml',\n u'2eur',\n u'30000ml',\n u'3000ml',\n u'300ml',\n u'308ml',\n u'310ml',\n u'314ml',\n u'318ml',\n u'33',\n u'330ml',\n u'349ml',\n u'35',\n u'355ml',\n u'365',\n u'375ml',\n u'4000ml',\n u'400ml',\n u'421',\n u'440ml',\n u'470ml',\n u'472ml',\n u'498ml',\n u'50',\n u'50000ml',\n u'5000ml',\n u'500ml',\n u'540ml',\n u'568ml',\n u'5e',\n u'6000ml',\n u'621',\n u'640ml',\n u'650ml',\n u'66',\n u'660ml',\n u'750ml',\n u'7pk',\n u'8\\xe5',\n u'9000ml',\n u'aas',\n u'abbaye',\n u'abbe',\n u'abdij',\n u'abdis',\n u'ac',\n u'achel',\n u'achelse',\n u'achilles',\n u'achouffe',\n u'ada',\n u'adams',\n u'adelardus',\n u'adriaans',\n u'adriaen',\n u'advokaat',\n u'affligem',\n u'agrum',\n u'agrumbocq',\n u'agrume',\n u'ahold',\n u'alberg',\n u'alcohol',\n u'aldi',\n u'ale',\n u'ales',\n u'alfa',\n u'alken',\n u'alsabieres',\n u'alvinne',\n u'amand',\n u'amber',\n u'ambre',\n u'ambrosius',\n u'amigo',\n u'amstel',\n u'anadolu',\n u'anchor',\n u'andelot',\n u'anders',\n u'andreas',\n u'angelus',\n u'anheuser',\n u'anker',\n u'annoeullin',\n u'anthisnes',\n u'antigoon',\n u'antwerps',\n u'antwerpse',\n u'apogee',\n u'apostel',\n u'apple',\n u'applebocq',\n u'apricot',\n u'arabier',\n u'arch',\n u'archiduc',\n u'arcobr\\xec\\xe3u',\n u'ardenne',\n u'arend',\n u'argus',\n u'arh',\n u'arm',\n u'aro',\n u'arogante',\n u'artevelde',\n u'arthurs',\n u'artisanale',\n u'artois',\n u'artus',\n u'asahi',\n u'askoy',\n u'assorted',\n u'assortment',\n u'atlas',\n u'au',\n u'aubel',\n u'aubert',\n u'augustijn',\n u'aulne',\n u'aurore',\n u'authentique',\n u'autruche',\n u'avena',\n u'averbode',\n u'avoinor',\n u'avouerie',\n u'azzurro',\n u'babylone',\n u'bacchus',\n u'baltika',\n u'banana',\n u'banded',\n u'bangelijke',\n u'barbar',\n u'barbe',\n u'barley',\n u'baron',\n u'basanina',\n u'based',\n u'basil',\n u'basilius',\n u'bass',\n u'bastogne',\n u'battin',\n u'bavaria',\n u'bavik',\n u'beaurinoise',\n u'beckers',\n u'becks',\n u'bedondaine',\n u'bedons',\n u'beer',\n u'beers',\n u'beersel',\n u'beker',\n u'bel',\n u'belenos',\n u'belfort',\n u'belgian',\n u'belgische',\n u'belgo',\n u'belgoo',\n u'bella',\n u'belle',\n u'bellegems',\n u'bellevaux',\n u'belma',\n u'belzebuth',\n u'ben',\n u'benno',\n u'benoit',\n u'bens',\n u'bernardus',\n u'berry',\n u'bersalis',\n u'bertha',\n u'bertinchamps',\n u'besos',\n u'best',\n u'betchard',\n u'beverages',\n u'bibco',\n u'bie',\n u'bier',\n u'bierbeekse',\n u'bierbrouwerij',\n u'biere',\n u'bieren',\n u'bieres',\n u'biermaekers',\n u'biernatie',\n u'bierreke',\n u'bierzolderke',\n u'big',\n u'bigote',\n u'bilberry',\n u'binchoise',\n u'bink',\n u'biofresh',\n u'biolegere',\n u'bir',\n u'birra',\n u'bisous',\n u'bister',\n u'bisterieuse',\n u'bitburger',\n u'bitter',\n u'bjj',\n u'black',\n u'blackcurrant',\n u'blanc',\n u'blanche',\n u'blancs',\n u'blaugies',\n u'blinde',\n u'bloc',\n u'block',\n u'bloemenbier',\n u'bloesem',\n u'blonde',\n u'blonder',\n u'blondine',\n u'blood',\n u'bloody',\n u'blue',\n u'blueberry',\n u'blues',\n u'bobeline',\n u'bock',\n u'bockor',\n u'bocq',\n u'boddingtons',\n u'boelens',\n u'boer',\n u'boeretang',\n u'boerinneken',\n u'boerken',\n u'bofferding',\n u'bohemia',\n u'bois',\n u'bok',\n u'bokkereyer',\n u'bokrijks',\n u'bolderiaan',\n u'bom',\n u'bon',\n u'boni',\n u'bonne',\n u'bons',\n u'bonsecours',\n u'book',\n u'booklet',\n u'boon',\n u'bootjes',\n u'bornem',\n u'bosbier',\n u'bossche',\n u'boston',\n u'botteresse',\n u'bottle',\n u'boucanier',\n u'bouillon',\n u'bouillonnaise',\n u'boulba',\n u'boulevard',\n u'bourgogne',\n u'boxer',\n u'brabandere',\n u'brahma',\n u'brasse',\n u'brasserie',\n u'brau',\n u'brauhaus',\n u'braven',\n u'bressene',\n u'bretagne',\n u'brew',\n u'breweries',\n u'brewers',\n u'brewery',\n u'brewing',\n u'brice',\n u'brigand',\n u'broeder',\n u'brogne',\n u'brooklyn',\n u'brouw',\n u'brouwer',\n u'brouwerij',\n u'brouwers',\n u'bruegel',\n u'brugge',\n u'brugs',\n u'brugse',\n u'bruin',\n u'brunehaut',\n u'brunette',\n u'brusseleir',\n u'brussels',\n u'brut',\n u'brute',\n u'bruxelles',\n u'bryggja',\n u'br\\xec\\xe3u',\n u'bucket',\n u'bud',\n u'budels',\n u'budelse',\n u'budget',\n u'budvar',\n u'budweiser',\n u'buffalo',\n u'bufo',\n u'bukske',\n u'bullseye',\n u'burgers',\n u'busch',\n u'bush',\n u'butlers',\n u'buval',\n u'bux',\n u'bzart',\n u'cacao',\n u'cachaca',\n u'cactus',\n u'cafes',\n u'caffreys',\n u'caipirinha',\n u'california',\n u'calister',\n u'calling',\n u'camaro',\n u'cambre',\n u'cambree',\n u'camille',\n u'campbells',\n u'can',\n u'canaille',\n u'candle',\n u'cantillon',\n u'cantiniere',\n u'car',\n u'cara',\n u'caracole',\n u'carlow',\n u'carlsberg',\n u'carolus',\n u'carrefour',\n u'carrieres',\n u'cassis',\n u'castelain',\n u'cats',\n u'caulier',\n u'cave',\n u'caves',\n u'cazeau',\n u'celis',\n u'celtik',\n u'celtika',\n u'cense',\n u'cepes',\n u'ceramic',\n u'cerise',\n u'cerises',\n u'cervoise',\n u'cesar',\n u'ch',\n u'chaamse',\n u'chambourlette',\n u'champigneulles',\n u'champs',\n u'chang',\n u'chapeau',\n u'chaperon',\n u'charlemagne',\n u'charleroi',\n u'charles',\n u'charmes',\n u'charrue',\n u'chat',\n u'chateau',\n u'chateaux',\n u'cherie',\n u'cherries',\n u'cherry',\n u'chestnut',\n u'chevetogne',\n u'chevremont',\n u'chimay',\n u'chinette',\n u'chocolate',\n u'chou',\n u'chouffe',\n u'cider',\n u'ciney',\n u'citroen',\n u'citron',\n u'citrus',\n u'claeyssens',\n u'claim',\n u'clausthaler',\n u'co',\n u'coast',\n u'coaster',\n u'coasters',\n u'coccinelle',\n u'cochon',\n u'cochonne',\n u'cochonnette',\n u'coconut',\n u'coffee',\n u'collaboration',\n u'collines',\n u'collins',\n u'colonel',\n u'colruyt',\n u'common',\n u'compagnie',\n u'company',\n u'condroz',\n u'contreras',\n u'coors',\n u'copper',\n u'cora',\n u'corbeau',\n u'corman',\n u'corne',\n u'cornelius',\n u'cornet',\n u'corona',\n u'corsaire',\n u'corsendonk',\n u'cott',\n u'cowboy',\n u'cranberry',\n u'cre',\n u'cress',\n u'cristal',\n u'crochon',\n u'croix',\n u'crombe',\n u'cru',\n u'cruzcampo',\n u'cubanisto',\n u'cum',\n u'curcu',\n u'curcuma',\n u'curim',\n u'curtius',\n u'cuvee',\n u'cuvees',\n u'dab',\n u'dagschotel',\n u'dame',\n u'damm',\n u'darbyste',\n u'dark',\n u'das',\n u'daussois',\n u'dc',\n u'de',\n u'debowe',\n u'deca',\n u'del',\n u'delhaize',\n u'delirium',\n u'delta',\n u'delvaux',\n u'demon',\n u'den',\n u'dendermonde',\n u'dendruppel',\n u'denise',\n u'dentergems',\n u'derby',\n u'des',\n u'deseveaux',\n u'desperados',\n u'deugniet',\n u'deum',\n u'deus',\n u'diabolici',\n u'diageo',\n u'diekirch',\n u'diemer',\n u'diest',\n u'diesterse',\n u'dieu',\n u'difcom',\n u'dijkwaert',\n u'dikke',\n u'dilewyns',\n u'diole',\n u'divine',\n u'djan',\n u'dog',\n u'dolen',\n u'dolle',\n u'dominus',\n u'donker',\n u'donn',\n u'dool',\n u'doppelbock',\n u'doppio',\n u'dormaal',\n u'dortmunder',\n u'dottignies',\n u'double',\n u'douce',\n u'doyen',\n u'dr',\n u'draak',\n u'drache',\n u'draft',\n u'drilles',\n u'dronkenput',\n u'drossaard',\n u'druppel',\n u'du',\n u'dubbel',\n u'dubuisson',\n u'duchesse',\n u'duff',\n u'duivelsbier',\n u'dulle',\n u'dunekeun',\n u'dunkelweizen',\n u'dupont',\n u'durboyse',\n u'dutch',\n u'duvel',\n u'duwac',\n u'd\\xe5',\n u'eau',\n u'ebly',\n u'ecaussines',\n u'ecaussinnes',\n u'echasse',\n u'echte',\n u'edler',\n u'eecke',\n u'eentje',\n u'eeuwige',\n u'efes',\n u'egotripel',\n u'eichbaum',\n u'eku',\n u'el',\n u'elderberry',\n u'elderflower',\n u'elephant',\n u'elfique',\n u'elixirs',\n u'ellezelloise',\n u'ellimac',\n u'en',\n u'ename',\n u'enfant',\n u'engelszell',\n u'enghien',\n u'epeautre',\n u'erdinger',\n u'erpe',\n u'erpigny',\n u'eschwege',\n u'esperance',\n u'esperluette',\n u'estaminet',\n u'estrella',\n u'estrellas',\n u'estribos',\n u'et',\n u'etre',\n u'eutropius',\n u'everyday',\n u'excel',\n u'excellence',\n u'exclusive',\n u'exotic',\n u'export',\n u'extra',\n u'ezel',\n u'fagnes',\n u'faro',\n u'fatale',\n u'felsgold',\n u'femme',\n u'ferme',\n u'ferre',\n u'ferrieres',\n u'fers',\n u'feuillien',\n u'fields',\n u'fier',\n u'filou',\n u'finest',\n u'fink',\n u'firminus',\n u'fisser',\n u'flanders',\n u'flandres',\n u'flash',\n u'fleurs',\n u'flierefluiter',\n u'floreffe',\n u'floris',\n u'florival',\n u'flower',\n u'flying',\n u'folie',\n u'fontane',\n u'fonteinen',\n u'food',\n u'force',\n u'forest',\n u'forestinne',\n u'forge',\n u'forgeronne',\n u'formidabel',\n u'fort',\n u'forts',\n u'fortwenger',\n u'fosters',\n u'fou',\n u'foudroyante',\n u'fourquets',\n u'fraise',\n u'fraises',\n u'framboise',\n u'framboises',\n u'framboizette',\n u'franchefleur',\n u'franchimont',\n u'franziskaner',\n u'free',\n u'freedom',\n u'frenesie',\n u'fresca',\n u'fresh',\n u'friart',\n u'froment',\n u'fromulus',\n u'fruit',\n u'fruitesse',\n u'fruitig',\n u'fruits',\n u'fulltime',\n u'fumette',\n u'funck',\n u'furetoise',\n u'fut',\n u'gageleer',\n u'galicia',\n u'garde',\n u'gauloise',\n u'gavroche',\n u'gayant',\n u'gayoule',\n u'geants',\n u'gembloux',\n u'gengeavia',\n u'gengoulf',\n u'genievre',\n u'genotschap',\n u'gents',\n u'gentse',\n u'georges',\n u'gerard',\n u'gerpinnoise',\n u'gerstel',\n u'ghislain',\n u'gift',\n u'gilbert',\n u'gildenbier',\n u'gin',\n u'ginder',\n u'ginette',\n u'gingerbread',\n u'givree',\n u'glass',\n u'glasses',\n u'glazen',\n u'glezia',\n u'gluck',\n u'gluten',\n u'go',\n u'goedendag',\n u'goedheilige',\n u'goedzak',\n u'gold',\n u'goldburg',\n u'goliath',\n u'gooisch',\n u'gooische',\n u'goose',\n u'gordon',\n u'goudale',\n u'gouden',\n u'goudpel',\n u'gouyasse',\n u'graal',\n u'grace',\n u'gracekennedy',\n u'grafenwalder',\n u'grain',\n u'granat',\n u'grand',\n u'grande',\n u'grandgousier',\n u'granit',\n u'grape',\n u'grapefruit',\n u'green',\n u'gregorius',\n u'grelotte',\n u'grenadine',\n u'gribousine',\n u'griet',\n u'grimbergen',\n u'griottes',\n u'grisette',\n u'groenendael',\n u'grognarde',\n u'grolsch',\n u'grosse',\n u'grotten',\n u'grottenbier',\n u'group',\n u'gruut',\n u'gr\\xec\\xe3fliches',\n u'gr\\xec\\xefndels',\n u'guarana',\n u'gueularde',\n u'gueuze',\n u'gueuzerie',\n u'guillotine',\n u'guinness',\n u'gulden',\n u'guldenberg',\n u'gummarus',\n u'gust',\n u'gypsy',\n u'haacht',\n u'haecht',\n u'hainaut',\n u'halen',\n u'halve',\n u'hapkin',\n u'haras',\n u'haspengauw',\n u'haspengouwse',\n u'hastiere',\n u'heer',\n u'heineken',\n u'heisse',\n u'hel',\n u'helene',\n u'helleketelbier',\n u'helles',\n u'hendrik',\n u'henninger',\n u'henri',\n u'henricus',\n u'herb',\n u'hercule',\n u'heritage',\n u'herkenrode',\n u'herten',\n u'hertog',\n u'hervoise',\n u'het',\n u'heure',\n u'heylissem',\n u'hijos',\n u'hinkelspel',\n u'hoegaarden',\n u'hof',\n u'hofbrouwerijke',\n u'hole',\n u'hollandia',\n u'holy',\n u'homme',\n u'hommel',\n u'honey',\n u'honnelles',\n u'honsebrouck',\n u'hop',\n u'hopperd',\n u'hops',\n u'hopus',\n u'hopvil',\n u'horne',\n u'horse',\n u'houblon',\n u'hougaerdse',\n u'houppe',\n u'houten',\n u'huisbrouwerij',\n u'huy',\n u'huyghe',\n u'hvad',\n u'ice',\n u'ichiban',\n u'icobes',\n u'idesbald',\n u'ij',\n u'ijwit',\n u'ijzeren',\n u'iki',\n u'imperatrice',\n u'imperial',\n u'importb',\n u'in',\n u'inbev',\n u'inc',\n u'india',\n u'inglorious',\n u'innotech',\n u'intermarche',\n u'ipa',\n u'island',\n u'islena',\n u'it',\n u'iv',\n u'jacob',\n u'jacobins',\n u'jacobsen',\n u'jacquie',\n u'jambe',\n u'jamboise',\n u'jan',\n u'jandrain',\n u'jandrenouille',\n u'jazz',\n u'jeanneke',\n u'jessenhofke',\n u'jilles',\n u'john',\n u'jonquille',\n u'jonquilles',\n u'jopen',\n u'joseph',\n u'joup',\n u'joyeux',\n u'jozef',\n u'judas',\n u'jules',\n u'julius',\n u'jupiler',\n u'kaiser',\n u'kanunnik',\n u'kapittel',\n u'karamalz',\n u'karl',\n u'karlsberg',\n u'karlsquell',\n u'karmeliet',\n u'kastaar',\n u'kasteel',\n u'kazematten',\n u'keg',\n u'kekette',\n u'kerkom',\n u'kerst',\n u'keyte',\n u'kievit',\n u'kilkenny',\n u'killer',\n u'kingfisher',\n u'kings',\n u'kingsbr\\xec\\xe3u',\n u'kirin',\n u'kirsche',\n u'klets',\n u'klevere',\n u'kluis',\n u'koeketiene',\n u'kompel',\n u'koninck',\n u'kop',\n u'kopstoot',\n u'krico',\n u'kriek',\n u'krieken',\n u'kronenbourg',\n u'kroon',\n u'kr\\xec\\xefger',\n u'kulmbacher',\n u'kustbrouwerij',\n u'kwak',\n u'kwaremont',\n u'kweeperen',\n u'kweiker',\n u'la',\n u'lacs',\n u'lager',\n u'lambic',\n u'lambiek',\n u'lamme',\n u'lamoral',\n u'landen',\n u'landewyck',\n u'lands',\n u'landtsheer',\n u'lapin',\n u'larogante',\n u'laude',\n u'lazarus',\n u'le',\n u'leau',\n u'lech',\n u'leeuw',\n u'lefebvre',\n u'leffe',\n u'legacy',\n u'legende',\n u'legendes',\n u'legia',\n u'leireken',\n u'leite',\n u'lekske',\n u'lemon',\n u'leopold7',\n u'lepers',\n u'leroy',\n u'les',\n u'lesse',\n u'leute',\n u'levrette',\n u'leyerth',\n u'li',\n u'librije',\n u'lichte',\n u'lidl',\n u'liefde',\n u'liefmans',\n u'liege',\n u'liegeoise',\n u'lienne',\n u'lieven',\n u'light',\n u'lille',\n u'lily',\n u'limburgse',\n u'lime',\n u'lindemans',\n u'lion',\n u'lips',\n u'liquor',\n u'liter',\n u'livinus',\n u'liza',\n u'll',\n u'loburg',\n u'local',\n u'lochristi',\n u'loetepoepe',\n u'longhora',\n u'longhorn',\n u'lorejas',\n u'loterbol',\n u'loufoque',\n u'louis',\n u'lousberg',\n u'louwaege',\n u'low',\n u'lucien',\n ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1658"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5423x1658 sparse matrix of type '<type 'numpy.int64'>'\n\twith 71557 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the documents in the training data to a document-term matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass classufication is not supported (probably) in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5423, 1658) (5423,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train the model\n",
    "print X_train_vectorized.shape, y_train.shape\n",
    "model = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AUC: ', array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ..., \n       [0, 0, 0, ..., 3, 0, 0],\n       [0, 0, 0, ..., 0, 1, 0],\n       [0, 0, 0, ..., 0, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "# print('AUC: ', roc_auc_score(y_test, predictions))\n",
    "print('AUC: ', confusion_matrix(y_test, predictions))\n",
    "\n",
    "# roc = {label: [] for label in y_test.unique()}\n",
    "# for label in y_test.unique():\n",
    "#     model = LogisticRegression()\n",
    "#     model.fit(X_train_vectorized, y_train == label)\n",
    "#     predictions_proba = model.predict_proba(X_test)\n",
    "#     roc[label] += roc_auc_score(y_test, predictions_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-aa8180282fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNaiveBayesClassifier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/nltk/classify/naivebayes.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Count up how many times each feature value occurred, given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# the label and featurename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mlabel_freqdist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier as nb\n",
    "from nltk.classify.util import accuracy\n",
    "cl = nb.train(X_train_vectorized)\n",
    "cl.classify(X_test)\n",
    "cl.classify_many(X_test)\n",
    "accuracy(cl, X_test)\n",
    "cl.labels()\n",
    "cl.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clfrSVM = svm.SVC(kernel='linear', C=0.1)\n",
    "clfrSVM.fit(X_train_vectorized, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (5423, 1658)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-44fa0a6928c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclfrNB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mclfrNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_vectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfrNB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    524\u001b[0m                         dtype=None)\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (5423, 1658)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn import naive_bayes as nb, metrics\n",
    "\n",
    "clfrNB = nb.MultinomialNB()\n",
    "clfrNB.fit(X_train_vectorized, y_train_vectorized)\n",
    "pred = clfrNB.predict(X_test)\n",
    "metrics.f1_score(y_test, pred, average='micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-2283616b07a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AUC: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m     return _average_binary_score(\n\u001b[1;32m    259\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/anaconda2/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Predict the transformed test documents\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "# Sort the coefficients from the model\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These reviews are treated the same by our current model\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the CountVectorizer to the training data specifiying a minimum \n",
    "# document frequency of 5 and extracting 1-grams and 2-grams\n",
    "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "predictions = model.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These reviews are now correctly identified\n",
    "print(model.predict(vect.transform(['not an issue, phone is working',\n",
    "                                    'an issue, phone is not working'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
